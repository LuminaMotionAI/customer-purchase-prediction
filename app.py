import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from src.data.data_processor import DataProcessor
from src.models.model import PurchasePredictor
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ›ï¸",
    layout="wide"
)

# íƒ€ì´í‹€ ë° ì„¤ëª…
st.title("êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.markdown("""
ì´ ëŒ€ì‹œë³´ë“œëŠ” ì‚¬ìš©ì í–‰ë™ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ë§¤ ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

[êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ](https://customer-purchase-prediction1.streamlit.app/)
""")

# ì‚¬ì´ë“œë°”
st.sidebar.title("ì„¤ì •")
sample_size = st.sidebar.slider("ìƒ˜í”Œ í¬ê¸°", 100, 1000, 500)
random_seed = st.sidebar.number_input("ëœë¤ ì‹œë“œ", 0, 100, 42)

# ë°ì´í„° ìƒì„± í•¨ìˆ˜
@st.cache_data
def generate_sample_data(n_samples, seed=42):
    np.random.seed(seed)
    return pd.DataFrame({
        'timestamp': pd.date_range(start='2024-01-01', periods=n_samples, freq='h'),
        'user_id': np.random.randint(1, 100, n_samples),
        'page_id': np.random.randint(1, 50, n_samples),
        'session_id': np.random.randint(1, 200, n_samples),
        'page_duration': np.random.randint(1, 3600, n_samples),
        'target': np.random.randint(0, 2, n_samples)
    })

# ë°ì´í„° ë° ëª¨ë¸ ì²˜ë¦¬
@st.cache_resource
def process_data_and_model(data):
    # ë°ì´í„° ì²˜ë¦¬ê¸°ì™€ ëª¨ë¸ ì´ˆê¸°í™”
    data_processor = DataProcessor()
    model = PurchasePredictor()
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    processed_data = data_processor.preprocess_data(data)
    feature_data = data_processor.create_features(processed_data)
    
    # ë°ì´í„° ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§
    X_train, X_test, y_train, y_test = data_processor.split_data(feature_data, 'target')
    X_train_scaled, X_test_scaled = data_processor.scale_features(X_train, X_test)
    
    # ëª¨ë¸ í•™ìŠµ
    model.train(X_train_scaled, y_train)
    
    # ì˜ˆì¸¡ ë° í‰ê°€
    predictions = model.predict(X_test_scaled)
    metrics = model.evaluate(X_test_scaled, y_test)
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    feature_importance = model.get_feature_importance()
    
    return processed_data, feature_data, X_test, predictions, metrics, feature_importance

# ë©”ì¸ ì•± ë¡œì§
data = generate_sample_data(sample_size, random_seed)

with st.spinner("ë°ì´í„° ì²˜ë¦¬ ë° ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
    processed_data, feature_data, X_test, predictions, metrics, feature_importance = process_data_and_model(data)

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ë°ì´í„° ê°œìš”", "ëª¨ë¸ ì„±ëŠ¥", "íŠ¹ì„± ì¤‘ìš”ë„"])

# íƒ­ 1: ë°ì´í„° ê°œìš”
with tab1:
    st.header("ìƒ˜í”Œ ë°ì´í„°")
    st.dataframe(data.head(10))
    
    st.header("ì „ì²˜ë¦¬ëœ ë°ì´í„°")
    st.dataframe(processed_data.head(10))
    
    st.header("ìƒì„±ëœ íŠ¹ì„±")
    st.dataframe(feature_data.head(10))
    
    # ì‹œê°„ëŒ€ë³„ í˜ì´ì§€ ì²´ë¥˜ ì‹œê°„ ì‹œê°í™”
    st.subheader("ì‹œê°„ëŒ€ë³„ í‰ê·  í˜ì´ì§€ ì²´ë¥˜ ì‹œê°„")
    
    # ì›ë³¸ ë°ì´í„°ë¡œ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì§„í–‰ (processed_data ëŒ€ì‹  data ì‚¬ìš©)
    hourly_data = data.groupby(data['timestamp'].dt.hour)['page_duration'].mean().reset_index()
    hourly_data.columns = ['Hour', 'Average Page Duration']
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x='Hour', y='Average Page Duration', data=hourly_data, ax=ax)
    ax.set_xlabel('Hour of Day')
    ax.set_ylabel('Average Page Duration (seconds)')
    st.pyplot(fig)

# íƒ­ 2: ëª¨ë¸ ì„±ëŠ¥
with tab2:
    st.header("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("F1 Score", f"{metrics['f1_score']:.4f}")
    col2.metric("Precision", f"{metrics['precision']:.4f}")
    col3.metric("Recall", f"{metrics['recall']:.4f}")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
    st.subheader("ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ë¹„êµ")
    results_df = X_test.copy()
    results_df['actual'] = X_test.index.map(processed_data['target'].to_dict())
    results_df['predicted'] = predictions
    
    fig, ax = plt.subplots(figsize=(10, 6))
    conf_matrix = pd.crosstab(results_df['actual'], results_df['predicted'], 
                              rownames=['Actual'], colnames=['Predicted'], 
                              normalize='index')
    sns.heatmap(conf_matrix, annot=True, fmt='.2%', cmap='Blues', ax=ax)
    st.pyplot(fig)

# íƒ­ 3: íŠ¹ì„± ì¤‘ìš”ë„
with tab3:
    st.header("íŠ¹ì„± ì¤‘ìš”ë„")
    
    # íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    importance_df = pd.DataFrame({
        'Feature': list(feature_importance.keys()),
        'Importance': list(feature_importance.values())
    }).sort_values('Importance', ascending=False)
    
    # ë°” ì°¨íŠ¸ë¡œ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.barplot(x='Importance', y='Feature', data=importance_df, ax=ax)
    ax.set_title('Feature Importance')
    ax.set_xlabel('Importance')
    ax.set_ylabel('Feature')
    st.pyplot(fig)
    
    st.subheader("íŠ¹ì„± ì¤‘ìš”ë„ ë°ì´í„°")
    st.dataframe(importance_df)

# í‘¸í„°
st.markdown("---")
st.caption("Â© 2025 êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ | Created with Forezy") 
