import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from src.data.data_processor import DataProcessor
from src.models.model import PurchasePredictor
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ›ï¸",
    layout="wide"
)

# íƒ€ì´í‹€ ë° ì„¤ëª…
st.title("êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.markdown("""
ì´ ëŒ€ì‹œë³´ë“œëŠ” ì‚¬ìš©ì í–‰ë™ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ë§¤ ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

[êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ](https://customer-purchase-prediction1.streamlit.app/)
""")

# ì‚¬ì´ë“œë°”
st.sidebar.title("ì„¤ì •")
sample_size = st.sidebar.slider("ìƒ˜í”Œ í¬ê¸°", 100, 1000, 500)
random_seed = st.sidebar.number_input("ëœë¤ ì‹œë“œ", 0, 100, 42)

# ë°ì´í„° ìƒì„± í•¨ìˆ˜
@st.cache_data
def generate_sample_data(n_samples, seed=42):
    np.random.seed(seed)
    return pd.DataFrame({
        'timestamp': pd.date_range(start='2024-01-01', periods=n_samples, freq='h'),
        'user_id': np.random.randint(1, 100, n_samples),
        'page_id': np.random.randint(1, 50, n_samples),
        'session_id': np.random.randint(1, 200, n_samples),
        'page_duration': np.random.randint(1, 3600, n_samples),
        'target': np.random.randint(0, 2, n_samples)
    })

# ë°ì´í„° ë° ëª¨ë¸ ì²˜ë¦¬
@st.cache_resource(ttl=3600, max_entries=10)
def process_data_and_model(data):
    # ë°ì´í„° ì²˜ë¦¬ê¸°ì™€ ëª¨ë¸ ì´ˆê¸°í™”
    data_processor = DataProcessor()
    model = PurchasePredictor()
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    processed_data = data_processor.preprocess_data(data)
    feature_data = data_processor.create_features(processed_data)
    
    # ë°ì´í„° ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§
    X_train, X_test, y_train, y_test = data_processor.split_data(feature_data, 'target')
    X_train_scaled, X_test_scaled = data_processor.scale_features(X_train, X_test)
    
    # ëª¨ë¸ í•™ìŠµ
    model.train(X_train_scaled, y_train)
    
    # ì˜ˆì¸¡ ë° í‰ê°€
    predictions = model.predict(X_test_scaled)
    metrics = model.evaluate(X_test_scaled, y_test)
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    feature_importance = model.get_feature_importance()
    
    return processed_data, feature_data, X_test, predictions, metrics, feature_importance

# ë©”ì¸ ì•± ë¡œì§
data = generate_sample_data(sample_size, random_seed)

with st.spinner("ë°ì´í„° ì²˜ë¦¬ ë° ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
    processed_data, feature_data, X_test, predictions, metrics, feature_importance = process_data_and_model(data)

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ë°ì´í„° ê°œìš”", "ëª¨ë¸ ì„±ëŠ¥", "íŠ¹ì„± ì¤‘ìš”ë„"])

# íƒ­ 1: ë°ì´í„° ê°œìš”
with tab1:
    st.header("ë°ì´í„° íƒìƒ‰")
    
    # ìƒìœ„ ëª‡ ê°œì˜ í–‰ ë³´ê¸°
    st.subheader("ë°ì´í„° ìƒ˜í”Œ")
    st.dataframe(processed_data.head())
    
    # ê¸°ë³¸ í†µê³„ëŸ‰ ë³´ê¸°
    st.subheader("ê¸°ë³¸ í†µê³„ëŸ‰")
    st.dataframe(processed_data.describe())
    
    # ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
    st.subheader("ë°ì´í„° ì¸ì‚¬ì´íŠ¸")
    st.markdown("""
    ğŸ“Š **ì£¼ìš” ë°œê²¬:**
    - ì´ ë°ì´í„°ì…‹ì€ ê³ ê°ë³„ íŠ¹ì„±ê³¼ êµ¬ë§¤ ì—¬ë¶€ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    - ê¸°ë³¸ í†µê³„ëŸ‰ì„ í†µí•´ ê° íŠ¹ì„±ì˜ ë¶„í¬ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - íŠ¹ì„±ë“¤ ê°„ì˜ í¸ì°¨ê°€ ìˆìœ¼ë¯€ë¡œ, ëª¨ë¸ë§ ì „ì— ì •ê·œí™”/í‘œì¤€í™” ì‘ì—…ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    ğŸ’¡ **í™œìš© ë°©ì•ˆ:**
    - íŠ¹ì„±ë“¤ì˜ ë¶„í¬ë¥¼ íŒŒì•…í•˜ì—¬ ë§ˆì¼€íŒ… íƒ€ê²ŸíŒ…ì˜ ê¸°ì¤€ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ì´ìƒì¹˜(outlier)ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë°ì´í„° í’ˆì§ˆì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    # ì‹œê°„ëŒ€ë³„ í˜ì´ì§€ ì²´ë¥˜ ì‹œê°„ ì‹œê°í™”
    st.subheader("ì‹œê°„ëŒ€ë³„ í‰ê·  í˜ì´ì§€ ì²´ë¥˜ ì‹œê°„")
    
    # ì›ë³¸ ë°ì´í„°ë¡œ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì§„í–‰ (processed_data ëŒ€ì‹  data ì‚¬ìš©)
    hourly_data = data.groupby(data['timestamp'].dt.hour)['page_duration'].mean().reset_index()
    hourly_data.columns = ['Hour', 'Average Page Duration']
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x='Hour', y='Average Page Duration', data=hourly_data, ax=ax)
    ax.set_xlabel('Hour of Day')
    ax.set_ylabel('Average Page Duration (seconds)')
    st.pyplot(fig)

# íƒ­ 2: ëª¨ë¸ ì„±ëŠ¥
with tab2:
    st.header("ëª¨ë¸ ì„±ëŠ¥")
    
    # ì •í™•ë„ ê³„ì‚° ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
    # ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ ê³„ì‚°
    y_pred_binary = (predictions > 0.5).astype(int)
    accuracy = (y_pred_binary == X_test.index.map(processed_data['target'].to_dict())).mean()
    
    # ì„±ëŠ¥ ì§€í‘œ ë³´ì—¬ì£¼ê¸°
    st.subheader("ì„±ëŠ¥ ì§€í‘œ")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì •í™•ë„(Accuracy)", f"{accuracy:.2f}")
    with col2:
        st.metric("ì •ë°€ë„(Precision)", f"{metrics['precision']:.2f}")
    with col3:
        st.metric("ì¬í˜„ìœ¨(Recall)", f"{metrics['recall']:.2f}")
    with col4:
        st.metric("F1 ì ìˆ˜", f"{metrics['f1_score']:.2f}")
    
    # ì„±ëŠ¥ ì§€í‘œ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
    st.markdown("""
    ğŸ“Š **ëª¨ë¸ ì„±ëŠ¥ í•´ì„:**
    - **ì •í™•ë„(Accuracy)**: ì „ì²´ ì˜ˆì¸¡ ì¤‘ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ì˜ ë¹„ìœ¨ì…ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.
    - **ì •ë°€ë„(Precision)**: êµ¬ë§¤ë¡œ ì˜ˆì¸¡í•œ ê³ ê° ì¤‘ ì‹¤ì œë¡œ êµ¬ë§¤í•œ ê³ ê°ì˜ ë¹„ìœ¨ì…ë‹ˆë‹¤. ë§ˆì¼€íŒ… ë¹„ìš© ìµœì í™”ì— ì¤‘ìš”í•©ë‹ˆë‹¤.
    - **ì¬í˜„ìœ¨(Recall)**: ì‹¤ì œ êµ¬ë§¤ ê³ ê° ì¤‘ ëª¨ë¸ì´ ì •í™•íˆ ì‹ë³„í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤. ì ì¬ ê³ ê°ì„ ë†“ì¹˜ì§€ ì•ŠëŠ”ë° ì¤‘ìš”í•©ë‹ˆë‹¤.
    - **F1 ì ìˆ˜**: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· ìœ¼ë¡œ, ë‘ ì§€í‘œ ê°„ì˜ ê· í˜•ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    
    ğŸ’¡ **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸:**
    - ì¬í˜„ìœ¨ì´ ë‚®ë‹¤ë©´ ì‹¤ì œ êµ¬ë§¤ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ê³ ê°ì„ ë†“ì¹˜ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ì •ë°€ë„ê°€ ë‚®ë‹¤ë©´ ë§ˆì¼€íŒ… ë¹„ìš©ì´ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•Šê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ì´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¼€íŒ… ì „ëµì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
    st.subheader("ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ë¹„êµ")
    results_df = X_test.copy()
    results_df['actual'] = X_test.index.map(processed_data['target'].to_dict())
    results_df['predicted'] = predictions

    # í˜¼ë™ í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤
    conf_matrix = pd.crosstab(results_df['actual'], results_df['predicted'], 
                              rownames=['Actual'], colnames=['Predicted'], 
                              normalize='index')

    # ëŒ€ì•ˆ 1: í˜¼ë™ í–‰ë ¬ì„ í‘œë¡œ í‘œì‹œ (ê°€ì¥ ê¹”ë”í•œ ë°©ë²•)
    st.write("#### í˜¼ë™ í–‰ë ¬ (ì •ê·œí™”ëœ %)")
    # í¼ì„¼íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
    conf_percent = conf_matrix.mul(100).round(1).astype(str) + '%'
    st.dataframe(conf_percent, use_container_width=True)

    # ëŒ€ì•ˆ 2: íˆíŠ¸ë§µ ê·¸ë¦¬ê¸° (í…ìŠ¤íŠ¸ ì—†ì´)
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(conf_matrix, cmap='Blues', ax=ax, annot=False, cbar=True)
    ax.set_xlabel('Predicted', fontsize=12)
    ax.set_ylabel('Actual', fontsize=12)
    # í‹± ìœ„ì¹˜ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
    ax.set_xticks([0.5, 1.5])
    ax.set_yticks([0.5, 1.5])
    ax.set_xticklabels(['0', '1'])
    ax.set_yticklabels(['0', '1'])
    st.pyplot(fig)

    # í˜¼ë™ í–‰ë ¬ í•´ì„ ì¶”ê°€
    st.write("#### í˜¼ë™ í–‰ë ¬ í•´ì„:")
    true_negative = conf_matrix.iloc[0, 0] if 0 in conf_matrix.index and 0 in conf_matrix.columns else 0
    false_positive = conf_matrix.iloc[0, 1] if 0 in conf_matrix.index and 1 in conf_matrix.columns else 0
    false_negative = conf_matrix.iloc[1, 0] if 1 in conf_matrix.index and 0 in conf_matrix.columns else 0
    true_positive = conf_matrix.iloc[1, 1] if 1 in conf_matrix.index and 1 in conf_matrix.columns else 0

    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„êµ¬ë§¤ (True Negative)", f"{true_negative:.1%}")
        st.metric("ì˜ëª» ì˜ˆì¸¡í•œ êµ¬ë§¤ (False Positive)", f"{false_positive:.1%}")
    with col2:
        st.metric("ì˜ëª» ì˜ˆì¸¡í•œ ë¹„êµ¬ë§¤ (False Negative)", f"{false_negative:.1%}")
        st.metric("ì •í™•íˆ ì˜ˆì¸¡í•œ êµ¬ë§¤ (True Positive)", f"{true_positive:.1%}")
    
    # í˜¼ë™ í–‰ë ¬ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
    st.markdown("""
    ğŸ“Š **í˜¼ë™ í–‰ë ¬ ì¸ì‚¬ì´íŠ¸:**
    - **True Negative**: êµ¬ë§¤í•˜ì§€ ì•Šì„ ê³ ê°ì„ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤. ë§ˆì¼€íŒ… ë¹„ìš© ì ˆê°ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
    - **False Positive**: êµ¬ë§¤í•˜ì§€ ì•Šì„ ê³ ê°ì„ êµ¬ë§¤í•  ê²ƒìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤. ì´ëŠ” ë§ˆì¼€íŒ… ì˜ˆì‚° ë‚­ë¹„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
    - **False Negative**: ì‹¤ì œ êµ¬ë§¤ ê³ ê°ì„ ë†“ì¹œ ë¹„ìœ¨ì…ë‹ˆë‹¤. ì´ëŠ” ì ì¬ì  ë§¤ì¶œ ì†ì‹¤ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
    - **True Positive**: ì‹¤ì œ êµ¬ë§¤ ê³ ê°ì„ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨ì…ë‹ˆë‹¤. íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… íƒ€ê²ŸíŒ…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    
    ğŸ’¡ **ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œì‚¬ì :**
    - False Positive ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ë§ˆì¼€íŒ… ì˜ˆì‚° ë‚­ë¹„ê°€ ë°œìƒí•©ë‹ˆë‹¤.
    - False Negative ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ë§¤ì¶œ ê¸°íšŒë¥¼ ë†“ì¹˜ê²Œ ë©ë‹ˆë‹¤.
    - ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆì¼€íŒ… ì „ëµì„ ìµœì í™”í•˜ì—¬ ROIë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

# íƒ­ 3: íŠ¹ì„± ì¤‘ìš”ë„
with tab3:
    st.header("íŠ¹ì„± ì¤‘ìš”ë„")
    
    # íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    importance_df = pd.DataFrame({
        'Feature': list(feature_importance.keys()),
        'Importance': list(feature_importance.values())
    }).sort_values('Importance', ascending=False)
    
    # ë°” ì°¨íŠ¸ë¡œ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.barplot(x='Importance', y='Feature', data=importance_df, ax=ax)
    ax.set_title('Feature Importance')
    ax.set_xlabel('Importance')
    ax.set_ylabel('Feature')
    st.pyplot(fig)
    
    st.subheader("íŠ¹ì„± ì¤‘ìš”ë„ ë°ì´í„°")
    st.dataframe(importance_df)
    
    # íŠ¹ì„± ì¤‘ìš”ë„ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
    st.subheader("íŠ¹ì„± ì¤‘ìš”ë„ ì¸ì‚¬ì´íŠ¸")
    
    # ì¤‘ìš” íŠ¹ì„± ì¶”ì¶œ (ìƒìœ„ 3ê°œ)
    top_features = importance_df.head(3)['Feature'].tolist()
    top_features_str = ', '.join([f"**{f}**" for f in top_features])
    
    st.markdown(f"""
    ğŸ“Š **ì£¼ìš” ë°œê²¬:**
    - ìƒìœ„ ì¤‘ìš” íŠ¹ì„±ì€ {top_features_str}ì…ë‹ˆë‹¤.
    - ì´ íŠ¹ì„±ë“¤ì´ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
    
    ğŸ’¡ **ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš© ë°©ì•ˆ:**
    - ì¤‘ìš”ë„ê°€ ë†’ì€ íŠ¹ì„±ì— ì§‘ì¤‘í•˜ì—¬ ë§ˆì¼€íŒ… ë©”ì‹œì§€ë¥¼ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ì œí’ˆ ê°œë°œ ë° ì„œë¹„ìŠ¤ ê°œì„  ì‹œ ì´ëŸ¬í•œ ì¤‘ìš” íŠ¹ì„±ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ì •ì˜ì— ì´ íŠ¹ì„±ë“¤ì„ í™œìš©í•˜ì—¬ ë” ì •êµí•œ íƒ€ê²ŸíŒ…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    - ë°ì´í„° ìˆ˜ì§‘ ì‹œ ì´ëŸ¬í•œ ì¤‘ìš” íŠ¹ì„±ì— ê´€ë ¨ëœ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™•ë³´í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.
    """)

# í‘¸í„°
st.markdown("---")
st.caption("Â© 2025 êµ¬ë§¤ ì˜ˆì¸¡ ë¶„ì„ ëŒ€ì‹œë³´ë“œ | Created with Forezy") 